# -*- coding: utf-8 -*-
"""Swgoh Spider Bot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mVONVNP-awk7hCEySvG0w-LlWt3Oxfxq
"""

import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
from datetime import datetime


def get_soup(url):
    html = requests.get(url)
    soup = BeautifulSoup(html.content, features='lxml')
    return soup


def get_ally_code_list(soup):
    ally_code_list = []
    for x in soup.find_all('tr'):
        link = x.find('a')
        if link is not None:
            href = link.get('href')
            if href is not None:
                ally_code_list.append(href)
    return ally_code_list


def get_tw_df(guild_url):
    tw_url = guild_url + 'tw-history/'
    tw_soup = get_soup(tw_url)
    # Get tw results
    tw_results = [x.text for x in [x.find('span') for x in tw_soup.find_all('tr')][10:]]
    # Get tw opponents
    tw_opponents = [x.find_all('a')[1].text for x in tw_soup.find_all('tr')][10:]
    # Get tw opponents GP
    tw_opponents_gps = [int(x.find_all('td')[2].text.replace('\n', '')
                            .replace(',', '')) for x in tw_soup.find_all('tr')][10:]
    # Get tw opponent scores
    tw_opponents_scores = [x.find_all('td')[3].text.replace(',', '')
                           .split('-')[-1].strip() for x in tw_soup.find_all('tr')][10:]
    # Get tw guild scores
    tw_guild_scores = [x.find_all('td')[3].text.replace(',', '').split('-')[0]
                       .strip() for x in tw_soup.find_all('tr')][10:]
    # Get tw dates
    tw_dates = [x.find_all('td')[-2].text for x in tw_soup.find_all('tr')][10:]
    # Get tw GP
    tw_gps = [x.find_all('td')[-1].text.replace(',', '') for x in tw_soup.find_all('tr')][10:]

    # Format non string data
    tw_opponents_gps = [int(x) for x in tw_opponents_gps]
    tw_opponents_scores = [int(x) for x in tw_opponents_scores]
    tw_guild_scores = [int(x) for x in tw_guild_scores]
    tw_gps = [int(x) for x in tw_gps]
    tw_dates = [datetime.strptime(x, "%Y-%m-%d").date() for x in tw_dates]

    # Create dictionary
    tw_dct = {
        'result': tw_results,
        'opponent': tw_opponents,
        'opponent_gp': tw_opponents_gps,
        'opponent_score': tw_opponents_scores,
        'guild_score': tw_guild_scores,
        'guild_gp': tw_gps,
        'date': tw_dates
    }

    # Convert dictionary to DataFrame
    df_tw = pd.DataFrame(tw_dct)
    return df_tw


def get_tb_df(guild_url):
    tb_url = guild_url + 'tb-history/'
    tb_soup = get_soup(tb_url)
    # Get tb names
    tb_names = [x.find('td').text.replace('\n', '') for x in tb_soup.find_all('tr')]
    # Get tb stars
    tb_stars = [x.find_all('td')[1].text.replace('\n', '') for x in tb_soup.find_all('tr')]
    # Get tb dates
    tb_dates = [x.find_all('td')[2].text for x in tb_soup.find_all('tr')]

    # Format non string data
    tb_stars = [int(x) for x in tb_stars]
    tb_dates = [datetime.strptime(x, "%Y-%m-%d").date() for x in tb_dates]

    # Create dictionary
    tb_dct = {
        'name': tb_names,
        'stars': tb_stars,
        'date': tb_dates
    }

    # Convert dictionary to DataFrame
    df_tb = pd.DataFrame(tb_dct)
    return df_tb


def get_raid_df(guild_url):
    raid_url = guild_url + 'raid-history/'
    raid_soup = get_soup(raid_url)

    # Get raid outcomes
    raid_outcomes = [x.find('span').text for x in raid_soup.find_all('tr')]
    # Get raid names
    raid_names = [x.find('a').text for x in raid_soup.find_all('tr')]
    # Get raid scores
    raid_scores = [x.find_all('td')[2].text.replace('\n', '').replace(',', '') for x in raid_soup.find_all('tr')]
    # Get raid attacking members
    raid_attacking_members = [x.find_all('td')[3].text.replace('\n', '') for x in raid_soup.find_all('tr')]
    # Get raid dates
    raid_dates = [x.find_all('td')[4].text.replace('\n', '') for x in raid_soup.find_all('tr')]

    # Format non string data
    raid_scores = [int(x) if x.isdigit() else None for x in raid_scores]
    raid_attacking_members = [int(x) for x in raid_attacking_members]
    raid_dates = [datetime.strptime(x, "%Y-%m-%d").date() for x in raid_dates]

    # Create dictionary
    raid_dct = {
        'outcome': raid_outcomes,
        'name': raid_names,
        'score': raid_scores,
        'attacking_members': raid_attacking_members,
        'date': raid_dates
    }

    # Convert dictionary to DataFrame
    df_raid = pd.DataFrame(raid_dct)

    return df_raid


def get_account_df(filtered_data, ally_code_list):
    ally_codes = [x.replace('/', '').replace('p', '') for x in ally_code_list]  # Cleaning ally code
    # Start lists
    account_names, titles, roles, fleet_arena_ranks, arena_ranks, gps, prs, ga_leagues = [], [], [], [], [], [], [], []
    # Get data for each account
    for account in filtered_data:
        # Get account_name
        account_names.append(account[0])

        # Get title
        titles.append(account[1])

        # Get rol
        roles.append(account[-1])

        # Get fleet arena rank & arena rank
        fleet_arena_ranks.append(int(account[-2]))
        arena_ranks.append(int(account[-3]))

        # Get GP, PRS y GA league
        gps.append(account[2])
        ga_prs = account[3].split('-')
        prs.append(int(ga_prs[0].strip()))
        ga_leagues.append(ga_prs[1].strip())

    # Create dictionary
    account_dct = {
        'ally_code': ally_codes,
        'account': account_names,
        'title': titles,
        'GP': gps,
        'role': roles,
        'arena_rank': arena_ranks,
        'fleet_arena_rank': fleet_arena_ranks,
        'player_rating_skill': prs,
        'GA_division': ga_leagues
    }

    # Convert dictionary to DataFrame
    df_account = pd.DataFrame(account_dct)

    return df_account, account_names


def get_ships_data(i, ally_code_list, account_names, ships_data):
    ship_url = 'https://swgoh.gg{}ships/'.format(ally_code_list[i])
    ship_soup = get_soup(ship_url)
    ship_roster = ship_soup.find_all('div', {'class': 'col-sm-6 col-md-6 col-lg-4'})

    for ship in ship_roster:
        ships_data['account'].append(account_names[i])
        # Get ship side
        ship_side = str(ship.find('div', class_='collection-ship').get('class')[-1]).replace('collection-ship-',
                                                                                             '').replace('-side',
                                                                                                         '')
        ships_data['side'].append(ship_side)
        # Get ship name
        ship_name = ship.find('a', class_='collection-ship-name-link').text.strip()
        ships_data['name'].append(ship_name)
        # Get ship stars
        ship_stars = len(ship.find_all('div', class_='ship-portrait__star'))
        ships_data['stars'].append(ship_stars)
        # Get ship lvl
        ship_lvl = ship.find('div', class_='ship-portrait__level').text.strip()
        ships_data['level'].append(ship_lvl)
        # Get ship gp
        gp_title = ship.find('div', class_='collection-char-gp')['title']
        ship_gp = gp_title.split()[1]
        ships_data['gp'].append(ship_gp)
        # Get ship img
        ship_img = ship.find('img', class_='ship-portrait__img').get('src')
        ships_data['img'].append(ship_img)
        # Get ship pilots
        ship_pilots = [pilot['title'] for pilot in ship.find_all('div', class_='character-portrait')]
        ships_data['pilot'].append(ship_pilots)
    return ships_data


def get_units_data(i, ally_code_list, account_names, units_data):
    unit_url = 'https://swgoh.gg{}characters/'.format(ally_code_list[i])
    unit_soup = get_soup(unit_url)
    unit_roster = unit_soup.find_all('div', {'class': 'col-xs-6 col-sm-3 col-md-3 col-lg-2'})
    # Get data of units
    for unit in unit_roster:
        units_data['account'].append(account_names[i])
        # Get names
        name = unit.find('div', class_='collection-char-name').get_text(strip=True)
        units_data['name'].append(name)
        # Get if dark or light Side
        match = re.search(r'collection-char-(\w+)-side', str(unit))
        if match:
            side = match.group(1)
        else:
            side = None
        units_data['side'].append(side)
        # Get amount of stars
        star = str(unit).count('<div class="character-portrait__star character-portrait__star--size-normal"></div>')
        units_data['stars'].append(star)
        # Get unit lvl
        regex = re.compile(r'character-portrait__level character-portrait__level--size-normal">\s*(\d+)\s*',
                           re.IGNORECASE)
        match = regex.search(str(unit))
        if match:
            level = int(match.group(1))
        else:
            level = 85
        units_data['level'].append(level)
        # Get gear tier
        p = r'character-portrait__gframe character-portrait__gframe--size-normal character-portrait__gframe--tier-(\d+)'
        regex = re.compile(p, re.IGNORECASE)
        match = regex.search(str(unit))
        if match:
            gear = int(match.group(1))
        else:
            gear = 13
        units_data['gear'].append(gear)
        # Get relic Tier
        regex = re.compile(r'character-portrait__relic[^>]*>\s*(\d+)', re.IGNORECASE)
        match = regex.search(str(unit))
        if match:
            relic = int(match.group(1))
        else:
            relic = 0
        units_data['relic'].append(relic)
        # Get zetas
        regex = re.compile(r'character-portrait__zeta[^>]*>\s*(\d+)', re.IGNORECASE)
        match = regex.search(str(unit))
        if match:
            zeta = int(match.group(1))
        else:
            zeta = 0
        units_data['zetas'].append(zeta)
        # Get omicrons
        regex = re.compile(r'character-portrait__omicron-count">(\d+)<', re.IGNORECASE)
        match = regex.search(str(unit))
        if match:
            omi = int(match.group(1))
        else:
            omi = 0
        units_data['omicrons'].append(omi)
        # Get img url
        match = re.search(r'<img.*?src="(.*?)".*?>', str(unit))
        if match:
            src = match.group(1)
        else:
            src = None
        units_data['img'].append(src)
        # Get unit gp
        gp_title = [x.find('div', class_='collection-char-gp')['title'] for x in
                    unit_soup.find_all('div', {'class': 'col-xs-6 col-sm-3 col-md-3 col-lg-2'})][0]
        unit_gp = int(gp_title.split()[1].replace(',', ''))
        units_data['gp'].append(unit_gp)
    return units_data


def get_unit_and_ship_df(ally_code_list, account_names):
    # Start dct
    units_data = {
        'account': [],
        'name': [],
        'side': [],
        'stars': [],
        'level': [],
        'gear': [],
        'relic': [],
        'zetas': [],
        'omicrons': [],
        'img': [],
        'gp': []
    }
    ships_data = {
        'account': [],
        'name': [],
        'side': [],
        'stars': [],
        'level': [],
        'gp': [],
        'pilot': [],
        'img': []
    }

    # Get data of each account
    for i in range(len(account_names)):
        print(f'Registrando a {account_names[i]}')
        # Get units data
        units_data = get_units_data(i, ally_code_list, account_names, units_data)
        # Get Ships Data
        ships_data = get_ships_data(i, ally_code_list, account_names, ships_data)
    # Convert dictionary to DataFrame
    df_units = pd.DataFrame(units_data)
    df_ships = pd.DataFrame(ships_data)

    return df_units, df_ships


def create_report(guild_name, current_date, df, report):
    file_name = guild_name + '_' + report + '_Data_' + str(current_date) + '.csv'
    df.to_csv(file_name, index=False, sep=';', encoding='utf-8')


def main():
    """# Get Guild Data"""

    guild_url = 'https://swgoh.gg/g/WzhVGBluRkaYJyFUpWY17A/'
    guild_soup = get_soup(guild_url)

    # Get guild name & current date
    guild_name = guild_soup.find('title').text.replace('SWGOH.GG', '').replace('·', '').strip().replace(' ', '_')
    current_date = datetime.now().date()

    # Get ally code for url
    ally_code_list = get_ally_code_list(guild_soup)

    # Get TW History
    df_tw = get_tw_df(guild_url)

    # Get TB History
    df_tb = get_tb_df(guild_url)

    # Get Raid History
    df_raid = get_raid_df(guild_url)

    """# Get Account Data"""

    # Filtering data to work with
    filtered_data = []
    data = [x.text.split('\n') for x in guild_soup.find_all('tr')][1:]
    for item in data:
        filtered_data.append([x for x in item if x.strip()])

    # Get Account Data
    df_account, account_names = get_account_df(filtered_data, ally_code_list)

    """# Get Unit & Ship Data"""
    df_units, df_ships = get_unit_and_ship_df(ally_code_list, account_names)

    """# Create Files"""

    # Create Account Report
    create_report(guild_name, current_date, df_account, 'Accounts')

    # Create Unit Report
    create_report(guild_name, current_date, df_units, 'Units')

    # Create Ships Report
    create_report(guild_name, current_date, df_ships, 'Ships')

    # Create TW Report
    create_report(guild_name, current_date, df_tw, 'TW')

    # Create TB Report
    create_report(guild_name, current_date, df_tb, 'TB')

    # Create Raid Report
    create_report(guild_name, current_date, df_raid, 'Raid')

    # Create xlsx
    file_name = guild_name + '_Reports_' + str(current_date) + '.xlsx'
    with pd.ExcelWriter(file_name) as writer:
        # First page df_account
        df_account.to_excel(writer, sheet_name='Accounts_Report', index=False)
        # Second page df_units
        df_units.to_excel(writer, sheet_name='Units_Report', index=False)
        # Third page df_ships
        df_ships.to_excel(writer, sheet_name='Ships_Report', index=False)
        # Fourth page df_tw
        df_tw.to_excel(writer, sheet_name='TW_Report', index=False)
        # Fifth page df_tb
        df_tb.to_excel(writer, sheet_name='TB_Report', index=False)
        # Sixth page df_raid
        df_raid.to_excel(writer, sheet_name='Raid_Report', index=False)


if __name__ == "__main__":
    main()
